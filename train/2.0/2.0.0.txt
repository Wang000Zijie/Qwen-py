# finetune_qwen_a800.py
import os
import json
from dataclasses import dataclass
from typing import Dict, Sequence, Any, Optional
from torch.utils.data import Dataset as TorchDataset
import torch
from modelscope import AutoTokenizer, AutoModelForCausalLM as MSAutoModelForCausalLM
from transformers import (
    TrainingArguments,
    Trainer,
    DataCollatorForSeq2Seq,
    EarlyStoppingCallback,
    get_cosine_schedule_with_warmup,
)
from peft import LoraConfig, get_peft_model, TaskType
import logging

# --- 1. 配置日志 ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- 2. 配置参数 ---
@dataclass
class FinetuneConfig:
    # 模型配置 (使用 ModelScope ID)
    model_name_or_path: str = "qwen/Qwen2.5-3B-Instruct"
    trust_remote_code: bool = True

    # 数据配置 (请根据您的实际路径修改)
    train_file: str = "/home/shuzhisuo/wzj/qwen-3B/train.jsonl"
    val_file: str = "/home/shuzhisuo/wzj/qwen-3B/val.jsonl"
    
    # 输出配置 (请根据您的实际路径修改)
    output_dir: str = "/home/shuzhisuo/wzj/qwen-3B/qwen2_5_3b_lora_a800"
    
    # LoRA 配置
    lora_r: int = 8  # 在 A800 上可以使用稍大的秩
    lora_alpha: int = 16
    lora_dropout: float = 0.05
    # Qwen2 常见的注意力层
    lora_target_modules: Sequence[str] = ("q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj")
    
    # 训练配置 (针对 A800 优化)
    per_device_train_batch_size: int = 4  # 增加 batch size
    per_device_eval_batch_size: int = 4
    gradient_accumulation_steps: int = 1  # 减少或取消梯度累积
    learning_rate: float = 1e-4
    num_train_epochs: int = 3  # 控制训练轮数
    # fp16: bool = False  # 不使用 FP16
    bf16: bool = True     # 推荐在 A800 上使用 BF16
    optim: str = "adamw_torch"
    
    # 调度器和早停
    lr_scheduler_type: str = "cosine"
    warmup_ratio: float = 0.1
    weight_decay: float = 0.01
    load_best_model_at_end: bool = True
    
    # 评估和保存 (注意参数名是 eval_strategy)
    eval_strategy: str = "steps"
    eval_steps: int = 500  # 增加评估间隔
    save_strategy: str = "steps"
    save_steps: int = 1000 # 增加保存间隔
    save_total_limit: int = 2
    logging_steps: int = 50
    logging_first_step: bool = True
    
    # 早停配置
    early_stopping_patience: int = 3
    
    # 其他
    dataloader_num_workers: int = 4 # 增加数据加载速度
    disable_tqdm: bool = False
    report_to: Optional[str] = None # 可设置为 "tensorboard"

# --- 3. 自定义数据集类 ---
class SupervisedDataset(TorchDataset):
    """监督微调数据集"""
    def __init__(self, raw_data, tokenizer: AutoTokenizer, max_len: int = 1024): # 增加序列长度
        super(SupervisedDataset, self).__init__()
        self.tokenizer = tokenizer
        self.raw_data = raw_data
        self.max_len = max_len
        self.cached_data_dict = {}

    def __len__(self):
        return len(self.raw_data)

    def __getitem__(self, i) -> Dict[str, torch.Tensor]:
        if i in self.cached_data_dict:
            return self.cached_data_dict[i]

        ret = preprocess([self.raw_data[i]], self.tokenizer, self.max_len)
        ret = {
            "input_ids": ret["input_ids"][0],
            "labels": ret["labels"][0],
            "attention_mask": ret["attention_mask"][0],
        }
        self.cached_data_dict[i] = ret
        return ret

def preprocess(sources: Sequence[Dict[str, str]], tokenizer: AutoTokenizer, max_len: int) -> Dict[str, Any]:
    """预处理数据，使用 Qwen 推荐的对话格式"""
    conversations = []
    for sample in sources:
        user_input = sample['query']
        bot_response = sample['response']
        
        # 使用 Qwen 模型常见的对话模板
        conversation = (
            f"<|im_start|>system\nYou are a helpful assistant.<|im_end|>\\n" # 注意 \n 的转义
            f"<|im_start|>user\\n{user_input}<|im_end|>\\n"
            f"<|im_start|>assistant\\n{bot_response}<|im_end|>"
        )
        conversations.append(conversation)
        
    tokenized = tokenizer(
        conversations,
        return_tensors="pt",
        padding="max_length",
        max_length=max_len,
        truncation=True,
    )
    
    labels = tokenized["input_ids"].clone()
    # labels[labels == tokenizer.pad_token_id] = -100 # 可选：忽略 padding token 的 loss
    
    return dict(
        input_ids=tokenized["input_ids"],
        labels=labels,
        attention_mask=tokenized["attention_mask"],
    )

# --- 4. 自定义 Trainer 以支持余弦退火 ---
class CustomTrainer(Trainer):
    def create_scheduler(self, num_training_steps: int, optimizer=None):
        """
        重写 create_scheduler 以使用自定义的余弦退火调度器。
        """
        if self.lr_scheduler is None:
            self.lr_scheduler = get_cosine_schedule_with_warmup(
                optimizer=self.optimizer if optimizer is None else optimizer,
                num_warmup_steps=self.args.get_warmup_steps(num_training_steps),
                num_training_steps=num_training_steps,
                num_cycles=0.5
            )
        return self.lr_scheduler

# --- 5. 主函数 ---
def main():
    # 1. 加载配置
    config = FinetuneConfig()
    logger.info("配置加载完成。")

    # 2. 确保输出目录存在
    os.makedirs(config.output_dir, exist_ok=True)
    
    # 3. & 4. 从 ModelScope 加载分词器和模型
    logger.info(f"正在从 ModelScope 加载模型和分词器: {config.model_name_or_path}")
    try:
        tokenizer = AutoTokenizer.from_pretrained(
            config.model_name_or_path,
            trust_remote_code=config.trust_remote_code,
            padding_side="right",
        )
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
        logger.info("分词器加载完成。")

        # 加载模型，利用 A800 资源
        model = MSAutoModelForCausalLM.from_pretrained(
            config.model_name_or_path,
            trust_remote_code=config.trust_remote_code,
            torch_dtype=torch.bfloat16 if config.bf16 else torch.float16, # 使用 BF16
            device_map="auto", # 让库自动处理设备映射
            # 如果想尝试 4bit 量化以进一步节省显存 (虽然 A800 显存大，但可以缩短训练时间)
            # load_in_4bit=True,
            # bnb_4bit_use_double_quant=True,
            # bnb_4bit_quant_type="nf4",
            # bnb_4bit_compute_dtype=torch.bfloat16 if config.bf16 else torch.float16,
        )
        logger.info("模型加载完成。")

    except Exception as e:
        logger.error(f"从 ModelScope 加载模型或分词器失败: {e}")
        raise

    # 5. 配置 LoRA
    logger.info("正在配置 LoRA...")
    lora_config = LoraConfig(
        r=config.lora_r,
        lora_alpha=config.lora_alpha,
        target_modules=config.lora_target_modules,
        lora_dropout=config.lora_dropout,
        bias="none",
        task_type=TaskType.CAUSAL_LM,
    )
    model = get_peft_model(model, lora_config)
    model.print_trainable_parameters()
    logger.info("LoRA 配置完成。")

    # 6. 加载和处理数据集
    logger.info("正在加载和处理数据集...")
    def load_jsonl_data(file_path):
        data = []
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    data.append(json.loads(line))
        return data

    train_raw_data = load_jsonl_data(config.train_file)
    val_raw_data = load_jsonl_data(config.val_file)
    logger.info(f"训练集大小: {len(train_raw_data)}, 验证集大小: {len(val_raw_data)}")

    train_dataset = SupervisedDataset(train_raw_data, tokenizer)
    val_dataset = SupervisedDataset(val_raw_data, tokenizer)
    logger.info("数据集处理完成。")

    # 7. 配置训练参数
    logger.info("正在配置训练参数...")
    # 动态构建 TrainingArguments 字典，以适应不同版本的 transformers
    training_args_dict = {
        "output_dir": config.output_dir,
        "per_device_train_batch_size": config.per_device_train_batch_size,
        "per_device_eval_batch_size": config.per_device_eval_batch_size,
        "gradient_accumulation_steps": config.gradient_accumulation_steps,
        "learning_rate": config.learning_rate,
        "num_train_epochs": config.num_train_epochs,
        # "fp16": config.fp16, # 不使用 FP16
        "bf16": config.bf16,   # 使用 BF16
        "optim": config.optim,
        # 使用正确的参数名 eval_strategy
        "eval_strategy": config.eval_strategy,
        "eval_steps": config.eval_steps,
        "save_strategy": config.save_strategy,
        "save_steps": config.save_steps,
        "save_total_limit": config.save_total_limit,
        "load_best_model_at_end": config.load_best_model_at_end,
        "metric_for_best_model": "eval_loss",
        "greater_is_better": False,
        "logging_steps": config.logging_steps,
        "logging_first_step": config.logging_first_step,
        "dataloader_num_workers": config.dataloader_num_workers,
        "disable_tqdm": config.disable_tqdm,
        "report_to": config.report_to,
        "remove_unused_columns": False,
        "warmup_ratio": config.warmup_ratio,
        "weight_decay": config.weight_decay,
        "lr_scheduler_type": config.lr_scheduler_type,
        # 可选：如果启用 4bit 量化，可能需要调整这些参数
        # "max_grad_norm": 0.3,
        # "adam_beta2": 0.95,
    }
    
    training_args = TrainingArguments(**training_args_dict)
    logger.info("训练参数配置完成。")

    # 8. 创建 Trainer
    logger.info("正在创建 Trainer...")
    trainer = CustomTrainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),
        callbacks=[EarlyStoppingCallback(early_stopping_patience=config.early_stopping_patience)]
    )
    logger.info("Trainer 创建完成。")

    # 9. 开始训练
    logger.info("开始训练...")
    train_result = trainer.train()
    logger.info("训练完成。")

    # 10. 保存模型和训练结果
    logger.info("正在保存最终模型...")
    trainer.save_model() # 保存 LoRA 权重和配置
    trainer.save_state() # 保存训练状态
    logger.info(f"模型和训练状态已保存至: {config.output_dir}")

    # 11. 记录训练指标
    metrics = train_result.metrics
    trainer.log_metrics("train", metrics)
    trainer.save_metrics("train", metrics)

if __name__ == "__main__":
    main()